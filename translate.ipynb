{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "translate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UAYUdYpQQtE"
      },
      "source": [
        "Setup: We want these packages installed beforehand"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1OoCMfKLJK3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f86d2a6d-e867-496f-b8a3-aca1713883bb"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import collections\n",
        "import pandas as pd\n",
        "import helper\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout, LSTM, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "!pip install visualkeras\n",
        "import visualkeras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "smoothie = SmoothingFunction().method4"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: visualkeras in /usr/local/lib/python3.7/dist-packages (0.0.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from visualkeras) (7.1.2)\n",
            "Requirement already satisfied: aggdraw>=1.3.11 in /usr/local/lib/python3.7/dist-packages (from visualkeras) (1.3.12)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from visualkeras) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tsuc38c3QWps"
      },
      "source": [
        "Loading in the smaller data-set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6lFvkcTJ354",
        "outputId": "b767c0a6-0873-4f25-8a53-5e2aa39b4698"
      },
      "source": [
        "!cp drive/MyDrive/ColabNotebooks/finalproject/small_vocab_en.txt .\n",
        "!cp drive/MyDrive/ColabNotebooks/finalproject/small_vocab_fr.txt .\n",
        "# load data\n",
        "english_sentences = []\n",
        "french_sentences = []\n",
        "with open('small_vocab_en.txt') as f:\n",
        "    for line in f:\n",
        "      english_sentences.append(line)\n",
        "\n",
        "with open('small_vocab_fr.txt') as f:\n",
        "    for line in f:\n",
        "      french_sentences.append(line)\n",
        "\n",
        "# print data stats\n",
        "english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n",
        "french_words_counter = collections.Counter([word for sentence in french_sentences for word in sentence.split()])\n",
        "\n",
        "# this code was taken from the data source\n",
        "print('{} English words.'.format(len([word for sentence in english_sentences for word in sentence.split()])))\n",
        "print('{} unique English words.'.format(len(english_words_counter)))\n",
        "print('10 Most common words in the English dataset:')\n",
        "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n",
        "print()\n",
        "print('{} French words.'.format(len([word for sentence in french_sentences for word in sentence.split()])))\n",
        "print('{} unique French words.'.format(len(french_words_counter)))\n",
        "print('10 Most common words in the French dataset:')\n",
        "print('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')\n",
        "\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1823250 English words.\n",
            "227 unique English words.\n",
            "10 Most common words in the English dataset:\n",
            "\"is\" \",\" \".\" \"in\" \"it\" \"during\" \"the\" \"but\" \"and\" \"sometimes\"\n",
            "\n",
            "1961295 French words.\n",
            "355 unique French words.\n",
            "10 Most common words in the French dataset:\n",
            "\"est\" \".\" \",\" \"en\" \"il\" \"les\" \"mais\" \"et\" \"la\" \"parfois\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIqmIn-GETj5"
      },
      "source": [
        "Loading in the much bigger europarl data-set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cii_ptLZJ7W3",
        "outputId": "599ea268-3621-4ab0-b9f0-61e99adcb5a8"
      },
      "source": [
        "# load doc into memory\n",
        "!cp drive/MyDrive/ColabNotebooks/finalproject/europarl-v7.fr-en.en .\n",
        "!cp drive/MyDrive/ColabNotebooks/finalproject/europarl-v7.fr-en.fr .\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, mode='rt', encoding='utf-8')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# split a loaded document into sentences\n",
        "def to_sentences(doc):\n",
        "\treturn doc.strip().split('\\n')\n",
        "\n",
        "# shortest and longest sentence lengths\n",
        "def sentence_lengths(sentences):\n",
        "\tlengths = [len(s.split()) for s in sentences]\n",
        "\treturn min(lengths), max(lengths)\n",
        "\n",
        "# load English data\n",
        "filename = 'europarl-v7.fr-en.en'\n",
        "doc = load_doc(filename)\n",
        "en_sentences = to_sentences(doc)\n",
        "minlen, maxlen = sentence_lengths(en_sentences)\n",
        "print('English data: en_sentences=%d, min=%d, max=%d' % (len(en_sentences), minlen, maxlen))\n",
        "\n",
        "# load French data\n",
        "filename = 'europarl-v7.fr-en.fr'\n",
        "doc = load_doc(filename)\n",
        "fr_sentences = to_sentences(doc)\n",
        "minlen, maxlen = sentence_lengths(fr_sentences)\n",
        "print('French data: fr_sentences=%d, min=%d, max=%d' % (len(fr_sentences), minlen, maxlen))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English data: en_sentences=2007723, min=0, max=668\n",
            "French data: fr_sentences=2007723, min=0, max=693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESeVO1o6EeVp"
      },
      "source": [
        "Tokenizing and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj73LVfLQvP8",
        "outputId": "a55553d9-b0c6-43ce-a139-fd2702476e42"
      },
      "source": [
        "# we need to tokenize the data, we will use word id's as \n",
        "# we want to predict what a word will be\n",
        "# a tokenizer converts each word into a word id. \n",
        "def tokenize(data):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(data)\n",
        "  return tokenizer.texts_to_sequences(data), tokenizer\n",
        "\n",
        "# we need to make sure all the sentences have the same the length, so we pad them\n",
        "def pad(data, maxlen=None):\n",
        "  return pad_sequences(data, maxlen=maxlen, padding='post')\n",
        "\n",
        "# preprocessing is equivalent to first tokenizing, and then padding all the sentences in the data set\n",
        "# we must also return the tokenizers so we can translate backward\n",
        "def preprocess(x, y):\n",
        "    preprocess_x, x_tk = tokenize(x)\n",
        "    preprocess_y, y_tk = tokenize(y)\n",
        "\n",
        "    preprocess_x = pad(preprocess_x)\n",
        "    preprocess_y = pad(preprocess_y)\n",
        "\n",
        "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
        "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
        "\n",
        "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
        "\n",
        "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer =\\\n",
        "    preprocess(english_sentences, french_sentences)\n",
        "\n",
        "proc_en, proc_fr, en_tokenizer, fr_tokenizer = preprocess(en_sentences[:1000], fr_sentences[:1000])\n",
        "\n",
        "max_en_sequence_length = proc_en.shape[1]\n",
        "max_fr_sequence_length = proc_fr.shape[1]\n",
        "en_vocab_size = len(en_tokenizer.word_index)\n",
        "fr_vocab_size = len(fr_tokenizer.word_index)\n",
        "\n",
        "# statistics\n",
        "print('Big Data Preprocessed')\n",
        "print(\"Max English sentence length:\", max_en_sequence_length)\n",
        "print(\"Max French sentence length:\", max_fr_sequence_length)\n",
        "print(\"English vocabulary size:\", en_vocab_size)\n",
        "print(\"French vocabulary size:\", fr_vocab_size)\n",
        "\n",
        "    \n",
        "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
        "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
        "english_vocab_size = len(english_tokenizer.word_index)\n",
        "french_vocab_size = len(french_tokenizer.word_index)\n",
        "\n",
        "# statistics\n",
        "print('Data Preprocessed')\n",
        "print(\"Max English sentence length:\", max_english_sequence_length)\n",
        "print(\"Max French sentence length:\", max_french_sequence_length)\n",
        "print(\"English vocabulary size:\", english_vocab_size)\n",
        "print(\"French vocabulary size:\", french_vocab_size)\n",
        "\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Big Data Preprocessed\n",
            "Max English sentence length: 116\n",
            "Max French sentence length: 133\n",
            "English vocabulary size: 3454\n",
            "French vocabulary size: 4443\n",
            "Data Preprocessed\n",
            "Max English sentence length: 15\n",
            "Max French sentence length: 21\n",
            "English vocabulary size: 199\n",
            "French vocabulary size: 344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHHGTk-EMmln"
      },
      "source": [
        "The out_to_txt function, takes in the logits from the model and returns the language representation of those logits based on the tokenizer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izjzfuc0iRtS"
      },
      "source": [
        "def out_to_txt(output, tokenizer):\n",
        "  # turns output from neural network into text using the tokenizer\n",
        "  index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "  index_to_words[0] = '<PAD>'\n",
        "  return ([index_to_words[prediction] for prediction in np.argmax(output, 1)])\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POHvj2H1SoMU"
      },
      "source": [
        "Building model 1, the simple GRU architecture. Please see paper for details. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IMQiV39EnDR"
      },
      "source": [
        "Reshaping the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E64aCY_LNDSv"
      },
      "source": [
        "tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n",
        "tmp_x = tmp_x[:, :, np.newaxis]\n",
        "tmp_en = pad(proc_en, max_fr_sequence_length)\n",
        "tmp_en = tmp_en[:, :, np.newaxis]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhCYMRx1jydC",
        "outputId": "4f6ba447-aca4-4b6c-f5cb-127a2b831827"
      },
      "source": [
        "def GRU_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    \n",
        "    # Hyperparameters\n",
        "    learning_rate = 0.005\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(GRU(256, input_shape=input_shape[1:], return_sequences=True))\n",
        "    model.add(GRU(256, return_sequences=True))\n",
        "    model.add(TimeDistributed(Dense(1024, activation='relu')))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax'))) \n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "simple_rnn_small = GRU_model(\n",
        "tmp_x.shape,\n",
        "max_french_sequence_length,\n",
        "english_vocab_size,\n",
        "french_vocab_size)\n",
        "\n",
        "simple_rnn_large = GRU_model(\n",
        "tmp_en.shape,\n",
        "max_fr_sequence_length,\n",
        "en_vocab_size,\n",
        "fr_vocab_size)\n",
        "\n",
        "\n",
        "print(simple_rnn_small.summary())\n",
        "print(simple_rnn_large.summary())\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_34 (GRU)                 (None, 21, 256)           198912    \n",
            "_________________________________________________________________\n",
            "gru_35 (GRU)                 (None, 21, 256)           394752    \n",
            "_________________________________________________________________\n",
            "time_distributed_34 (TimeDis (None, 21, 1024)          263168    \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 21, 1024)          0         \n",
            "_________________________________________________________________\n",
            "time_distributed_35 (TimeDis (None, 21, 344)           352600    \n",
            "=================================================================\n",
            "Total params: 1,209,432\n",
            "Trainable params: 1,209,432\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_36 (GRU)                 (None, 133, 256)          198912    \n",
            "_________________________________________________________________\n",
            "gru_37 (GRU)                 (None, 133, 256)          394752    \n",
            "_________________________________________________________________\n",
            "time_distributed_36 (TimeDis (None, 133, 1024)         263168    \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 133, 1024)         0         \n",
            "_________________________________________________________________\n",
            "time_distributed_37 (TimeDis (None, 133, 4443)         4554075   \n",
            "=================================================================\n",
            "Total params: 5,410,907\n",
            "Trainable params: 5,410,907\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA71iKQvNoRF"
      },
      "source": [
        "Fitting the model, see paper for details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfInxyFBNxAn",
        "outputId": "2333c37d-d652-4f12-ff0d-c03cddaa76fc"
      },
      "source": [
        "#from sklearn.model_selection import train_test_split\n",
        "#xgru_train, xgru_test, ygru_train, ygru_test = train_test_split(preproc_english_sentences, preproc_french_sentences, test_size=0.20, random_state=42)\n",
        "simple_rnn_small.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "108/108 [==============================] - 6s 32ms/step - loss: 2.7523 - accuracy: 0.4603 - val_loss: nan - val_accuracy: 0.6492\n",
            "Epoch 2/10\n",
            "108/108 [==============================] - 3s 26ms/step - loss: 1.1832 - accuracy: 0.6493 - val_loss: nan - val_accuracy: 0.6672\n",
            "Epoch 3/10\n",
            "108/108 [==============================] - 3s 26ms/step - loss: 1.0109 - accuracy: 0.6787 - val_loss: nan - val_accuracy: 0.7147\n",
            "Epoch 4/10\n",
            "108/108 [==============================] - 3s 26ms/step - loss: 0.8963 - accuracy: 0.7067 - val_loss: nan - val_accuracy: 0.7223\n",
            "Epoch 5/10\n",
            "108/108 [==============================] - 3s 26ms/step - loss: 0.8334 - accuracy: 0.7237 - val_loss: nan - val_accuracy: 0.7345\n",
            "Epoch 6/10\n",
            "108/108 [==============================] - 3s 26ms/step - loss: 0.7730 - accuracy: 0.7407 - val_loss: nan - val_accuracy: 0.7791\n",
            "Epoch 7/10\n",
            "108/108 [==============================] - 3s 26ms/step - loss: 0.7374 - accuracy: 0.7492 - val_loss: nan - val_accuracy: 0.7565\n",
            "Epoch 8/10\n",
            "108/108 [==============================] - 3s 26ms/step - loss: 0.6843 - accuracy: 0.7629 - val_loss: nan - val_accuracy: 0.7878\n",
            "Epoch 9/10\n",
            "108/108 [==============================] - 3s 26ms/step - loss: 0.6717 - accuracy: 0.7666 - val_loss: nan - val_accuracy: 0.7875\n",
            "Epoch 10/10\n",
            "108/108 [==============================] - 3s 26ms/step - loss: 0.6577 - accuracy: 0.7706 - val_loss: nan - val_accuracy: 0.8116\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdf49a5f190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J1fqamfNyQ1"
      },
      "source": [
        "Getting the predictions on the data-set from the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STFFVem1oWjJ"
      },
      "source": [
        "small_predictions = simple_rnn_small.predict(tmp_x)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vuS29uWOMWt"
      },
      "source": [
        "Evaluating the simple GRU model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bCb7GEDU_2u",
        "outputId": "168a5cf0-74f7-4464-e54a-a944f665081f"
      },
      "source": [
        "# prints example predictions with the correct ones for comparison\n",
        "def print_examples(model, data):\n",
        "  print(\"Prediction:\")\n",
        "  print(out_to_txt(model.predict(data[:1])[0], french_tokenizer))\n",
        "\n",
        "  print(\"\\nCorrect Translation:\")\n",
        "  print(french_sentences[:1])\n",
        "\n",
        "  print(\"\\nOriginal text:\")\n",
        "  print(english_sentences[:1])\n",
        "\n",
        "print_examples(simple_rnn_small, tmp_x)\n",
        "\n",
        "# removes the padding when comparing BLEU scores\n",
        "def remove_pad(predictions):\n",
        "  new_predictions = []\n",
        "  for i, prediction in enumerate(predictions):\n",
        "    new_prediction = []\n",
        "    for word in prediction:\n",
        "      if word == '<PAD>':\n",
        "        break\n",
        "      new_prediction.append(word)\n",
        "    new_predictions.append(new_prediction)\n",
        "  return new_predictions\n",
        "\n",
        "# turns the logits into actual french sentences\n",
        "def get_predictions(model, tokenizer, predictions):\n",
        "  new_predictions = []\n",
        "  print(predictions[0].shape)\n",
        "  for i, prediction in enumerate(predictions):\n",
        "     new_predictions.append(out_to_txt(prediction, tokenizer))\n",
        "  return new_predictions\n",
        "\n",
        "# calculates the overall BLEU score of the model\n",
        "def bleu_score(predictions, originals):\n",
        "  total = 0\n",
        "  for i, prediction in enumerate(predictions):\n",
        "    reference = [prediction]\n",
        "    candidate = originals[i].split()\n",
        "    score = sentence_bleu(reference, candidate, smoothing_function=smoothie)\n",
        "    total += score\n",
        "  return total / len(predictions) * 100\n",
        "\n",
        "\n",
        "simple_rnn_predictions = get_predictions(simple_rnn_small, french_tokenizer, small_predictions)\n",
        "y_predictions = french_sentences\n",
        "print(simple_rnn_predictions[0])\n",
        "print(y_predictions[0])\n",
        "\n",
        "print(\"this is the bleu score of the simpleRNN model\")\n",
        "print(bleu_score(remove_pad(simple_rnn_predictions), y_predictions))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction:\n",
            "['new', 'jersey', 'est', 'parfois', 'chaud', 'en', 'cours', 'automne', 'il', 'est', 'il', 'est', 'avril', 'en', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "\n",
            "Correct Translation:\n",
            "[\"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\\n\"]\n",
            "\n",
            "Original text:\n",
            "['new jersey is sometimes quiet during autumn , and it is snowy in april .\\n']\n",
            "(21, 344)\n",
            "['new', 'jersey', 'est', 'parfois', 'chaud', 'en', 'cours', 'automne', 'il', 'est', 'il', 'est', 'avril', 'en', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
            "\n",
            "this is the bleu score of the simpleRNN model\n",
            "22.89173961928556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXSOvpWkPZE0"
      },
      "source": [
        "Model 2: Simple enc-dec model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcJKloeSoKIy"
      },
      "source": [
        "def simple_encdec(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    learning_rate = 0.001\n",
        "\n",
        "    model = Sequential()\n",
        "    # Encoder\n",
        "    model.add(GRU(256, input_shape=input_shape[1:], go_backwards=True))\n",
        "    model.add(RepeatVector(output_sequence_length))\n",
        "    # Decoder\n",
        "    model.add(GRU(256, return_sequences=True))\n",
        "    model.add(TimeDistributed(Dense(1024, activation='relu')))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax')))\n",
        "\n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upjW2JG3PNZ0"
      },
      "source": [
        "Data Re-shaping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do4W6GcZ7unN"
      },
      "source": [
        "enc_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\n",
        "enc_x = enc_x.reshape((-1, preproc_french_sentences.shape[-2], 1))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkwq_ift_pFe",
        "outputId": "4a91a9cf-9e90-43ea-c251-30b854a7fe96"
      },
      "source": [
        "encdec_simple = encdec(\n",
        "    enc_x.shape,\n",
        "    preproc_french_sentences.shape[1],\n",
        "    len(english_tokenizer.word_index)+1,\n",
        "    len(french_tokenizer.word_index)+1)\n",
        "\n",
        "encdec_simple.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_38 (GRU)                 (None, 256)               198912    \n",
            "_________________________________________________________________\n",
            "repeat_vector_11 (RepeatVect (None, 21, 256)           0         \n",
            "_________________________________________________________________\n",
            "gru_39 (GRU)                 (None, 21, 256)           394752    \n",
            "_________________________________________________________________\n",
            "time_distributed_38 (TimeDis (None, 21, 1024)          263168    \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 21, 1024)          0         \n",
            "_________________________________________________________________\n",
            "time_distributed_39 (TimeDis (None, 21, 345)           353625    \n",
            "=================================================================\n",
            "Total params: 1,210,457\n",
            "Trainable params: 1,210,457\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gpjjOKMPkLs"
      },
      "source": [
        "Data fitting, and training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0KxozCSAQ9L",
        "outputId": "f89b73a5-9e74-47ab-cc03-e8e587238066"
      },
      "source": [
        "encdec_simple.fit(enc_x, preproc_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "108/108 [==============================] - 8s 51ms/step - loss: 3.0795 - accuracy: 0.4179 - val_loss: 1.7801 - val_accuracy: 0.5697\n",
            "Epoch 2/10\n",
            "108/108 [==============================] - 5s 46ms/step - loss: 1.7179 - accuracy: 0.5664 - val_loss: 1.4553 - val_accuracy: 0.6133\n",
            "Epoch 3/10\n",
            "108/108 [==============================] - 5s 46ms/step - loss: 1.4408 - accuracy: 0.6071 - val_loss: 1.3159 - val_accuracy: 0.6367\n",
            "Epoch 4/10\n",
            "108/108 [==============================] - 5s 46ms/step - loss: 1.3397 - accuracy: 0.6281 - val_loss: 1.2464 - val_accuracy: 0.6524\n",
            "Epoch 5/10\n",
            "108/108 [==============================] - 5s 46ms/step - loss: 1.2731 - accuracy: 0.6435 - val_loss: 1.1958 - val_accuracy: 0.6609\n",
            "Epoch 6/10\n",
            "108/108 [==============================] - 5s 45ms/step - loss: 1.2273 - accuracy: 0.6519 - val_loss: 1.1376 - val_accuracy: 0.6697\n",
            "Epoch 7/10\n",
            "108/108 [==============================] - 5s 46ms/step - loss: 1.1575 - accuracy: 0.6656 - val_loss: 1.0948 - val_accuracy: 0.6793\n",
            "Epoch 8/10\n",
            "108/108 [==============================] - 5s 46ms/step - loss: 1.1275 - accuracy: 0.6721 - val_loss: 1.1089 - val_accuracy: 0.6783\n",
            "Epoch 9/10\n",
            "108/108 [==============================] - 5s 46ms/step - loss: 1.1101 - accuracy: 0.6766 - val_loss: 1.0382 - val_accuracy: 0.6933\n",
            "Epoch 10/10\n",
            "108/108 [==============================] - 5s 46ms/step - loss: 1.0587 - accuracy: 0.6891 - val_loss: 1.0159 - val_accuracy: 0.7016\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa65653d890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEMIW7n9PoUs"
      },
      "source": [
        "Model 2 evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHu9XMvjQY3M"
      },
      "source": [
        "encdec_predictions = encdec_simple.predict(enc_x)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZfC5jo-Qm4M",
        "outputId": "bcc15c62-a909-4011-c729-d719e3385ddb"
      },
      "source": [
        "def get_predictions(model, tokenizer, predictions):\n",
        "  new_predictions = []\n",
        "  print(predictions[0].shape)\n",
        "  for i, prediction in enumerate(predictions):\n",
        "     new_predictions.append(out_to_txt(prediction, tokenizer))\n",
        "  return new_predictions\n",
        "\n",
        "def bleu_score(predictions, originals):\n",
        "  total = 0\n",
        "  for i, prediction in enumerate(predictions):\n",
        "    reference = [prediction]\n",
        "    candidate = originals[i].split()\n",
        "    score = sentence_bleu(reference, candidate, smoothing_function=smoothie)\n",
        "    total += score\n",
        "  return total / len(predictions) * 100\n",
        "\n",
        "encdec_predictions = get_predictions(encdec_simple, french_tokenizer, encdec_predictions)\n",
        "y_predictions = french_sentences\n",
        "\n",
        "\n",
        "\n",
        "print(\"this is the bleu score of the simple encdec model\")\n",
        "print(bleu_score((encdec_predictions), y_predictions))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21, 345)\n",
            "this is the bleu score of the simple encdec model\n",
            "0.3233405582777288\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nmKYoREScyd"
      },
      "source": [
        "Example outputs from model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFPZvqXCA7Fa",
        "outputId": "398e9114-0b3f-4371-ce3d-7998d6d2ad02"
      },
      "source": [
        "def print_examples(model, data):\n",
        "  print(\"Prediction:\")\n",
        "  print(out_to_txt(model.predict(data[:1])[0], french_tokenizer))\n",
        "\n",
        "  print(\"\\nCorrect Translation:\")\n",
        "  print(french_sentences[:1])\n",
        "\n",
        "  print(\"\\nOriginal text:\")\n",
        "  print(english_sentences[:1])\n",
        "\n",
        "print_examples(simple_rnn_small, tmp_x)\n",
        "\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction:\n",
            "['new', 'jersey', 'est', 'parfois', 'calme', 'au', 'mois', 'de', \"l'\", 'automne', 'il', 'est', 'avril', 'en', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "\n",
            "Correct Translation:\n",
            "[\"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\\n\"]\n",
            "\n",
            "Original text:\n",
            "['new jersey is sometimes quiet during autumn , and it is snowy in april .\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REiwxmMESiUj"
      },
      "source": [
        "Model 3: Combination encoder-decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqENDL6wCw_s"
      },
      "source": [
        "def combo_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    # Hyperparameters\n",
        "    learning_rate = 0.003 \n",
        "    model = Sequential()\n",
        "    # Embedding\n",
        "    model.add(Embedding(english_vocab_size, 128, input_length=input_shape[1],\n",
        "                         input_shape=input_shape[1:]))\n",
        "    # Encoder\n",
        "    model.add(Bidirectional(GRU(128)))\n",
        "    model.add(RepeatVector(output_sequence_length))\n",
        "    # Decoder\n",
        "    model.add(Bidirectional(GRU(128, return_sequences=True)))\n",
        "    model.add(TimeDistributed(Dense(512, activation='relu')))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax')))\n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6XC3ovJS1wa"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(preproc_english_sentences, preproc_french_sentences, test_size=0.20, random_state=42)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psO25R-cSrv9",
        "outputId": "1c0bec8f-f3fc-4792-e654-757a464b6992"
      },
      "source": [
        "improved_encdec = combo_model(x_train.shape,y_train.shape[1],\n",
        "                        len(english_tokenizer.word_index)+1,\n",
        "                        len(french_tokenizer.word_index)+1)\n",
        "\n",
        "improved_encdec.summary()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 15, 128)           25600     \n",
            "_________________________________________________________________\n",
            "bidirectional_16 (Bidirectio (None, 256)               198144    \n",
            "_________________________________________________________________\n",
            "repeat_vector_14 (RepeatVect (None, 21, 256)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_17 (Bidirectio (None, 21, 256)           296448    \n",
            "_________________________________________________________________\n",
            "time_distributed_44 (TimeDis (None, 21, 512)           131584    \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 21, 512)           0         \n",
            "_________________________________________________________________\n",
            "time_distributed_45 (TimeDis (None, 21, 345)           176985    \n",
            "=================================================================\n",
            "Total params: 828,761\n",
            "Trainable params: 828,761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3YWllfIVLmk",
        "outputId": "724880d6-a101-412c-8eee-68fa70d110e7"
      },
      "source": [
        "improved_encdec.fit(x_train, y_train, batch_size=1024, epochs=25, validation_split=0.2)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "87/87 [==============================] - 9s 42ms/step - loss: 3.2466 - accuracy: 0.4193 - val_loss: 1.6231 - val_accuracy: 0.5911\n",
            "Epoch 2/25\n",
            "87/87 [==============================] - 2s 29ms/step - loss: 1.5768 - accuracy: 0.5902 - val_loss: 1.2899 - val_accuracy: 0.6428\n",
            "Epoch 3/25\n",
            "87/87 [==============================] - 2s 29ms/step - loss: 1.2637 - accuracy: 0.6530 - val_loss: 1.0388 - val_accuracy: 0.7050\n",
            "Epoch 4/25\n",
            "87/87 [==============================] - 2s 29ms/step - loss: 1.0901 - accuracy: 0.6901 - val_loss: 0.9181 - val_accuracy: 0.7318\n",
            "Epoch 5/25\n",
            "87/87 [==============================] - 2s 29ms/step - loss: 0.9870 - accuracy: 0.7115 - val_loss: 0.8423 - val_accuracy: 0.7462\n",
            "Epoch 6/25\n",
            "87/87 [==============================] - 2s 29ms/step - loss: 0.8776 - accuracy: 0.7358 - val_loss: 0.7431 - val_accuracy: 0.7671\n",
            "Epoch 7/25\n",
            "87/87 [==============================] - 2s 29ms/step - loss: 0.7736 - accuracy: 0.7607 - val_loss: 0.6125 - val_accuracy: 0.8066\n",
            "Epoch 8/25\n",
            "87/87 [==============================] - 2s 29ms/step - loss: 0.6645 - accuracy: 0.7906 - val_loss: 0.6097 - val_accuracy: 0.8061\n",
            "Epoch 9/25\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.6058 - accuracy: 0.8057 - val_loss: 0.4904 - val_accuracy: 0.8404\n",
            "Epoch 10/25\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.6329 - accuracy: 0.7972 - val_loss: 0.3873 - val_accuracy: 0.8759\n",
            "Epoch 11/25\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.4484 - accuracy: 0.8545 - val_loss: 0.3332 - val_accuracy: 0.8928\n",
            "Epoch 12/25\n",
            "87/87 [==============================] - 2s 29ms/step - loss: 0.3982 - accuracy: 0.8695 - val_loss: 0.2717 - val_accuracy: 0.9155\n",
            "Epoch 13/25\n",
            "87/87 [==============================] - 2s 29ms/step - loss: 0.3202 - accuracy: 0.8976 - val_loss: 0.2550 - val_accuracy: 0.9241\n",
            "Epoch 14/25\n",
            "87/87 [==============================] - 2s 29ms/step - loss: 0.2975 - accuracy: 0.9079 - val_loss: 0.2287 - val_accuracy: 0.9309\n",
            "Epoch 15/25\n",
            "87/87 [==============================] - 2s 29ms/step - loss: 0.2587 - accuracy: 0.9210 - val_loss: 0.2385 - val_accuracy: 0.9270\n",
            "Epoch 16/25\n",
            "87/87 [==============================] - 2s 29ms/step - loss: 0.2528 - accuracy: 0.9212 - val_loss: 0.1606 - val_accuracy: 0.9531\n",
            "Epoch 17/25\n",
            "87/87 [==============================] - 2s 29ms/step - loss: 0.1929 - accuracy: 0.9411 - val_loss: 0.1551 - val_accuracy: 0.9555\n",
            "Epoch 18/25\n",
            "87/87 [==============================] - 3s 29ms/step - loss: 0.1806 - accuracy: 0.9452 - val_loss: 0.1542 - val_accuracy: 0.9534\n",
            "Epoch 19/25\n",
            "87/87 [==============================] - 2s 29ms/step - loss: 0.1845 - accuracy: 0.9428 - val_loss: 0.1378 - val_accuracy: 0.9601\n",
            "Epoch 20/25\n",
            "87/87 [==============================] - 3s 29ms/step - loss: 0.1527 - accuracy: 0.9531 - val_loss: 0.1274 - val_accuracy: 0.9613\n",
            "Epoch 21/25\n",
            "87/87 [==============================] - 2s 29ms/step - loss: 0.1466 - accuracy: 0.9548 - val_loss: 0.1254 - val_accuracy: 0.9645\n",
            "Epoch 22/25\n",
            "87/87 [==============================] - 2s 29ms/step - loss: 0.1338 - accuracy: 0.9586 - val_loss: 0.1219 - val_accuracy: 0.9637\n",
            "Epoch 23/25\n",
            "87/87 [==============================] - 2s 29ms/step - loss: 0.1320 - accuracy: 0.9595 - val_loss: 0.1109 - val_accuracy: 0.9673\n",
            "Epoch 24/25\n",
            "87/87 [==============================] - 2s 29ms/step - loss: 0.1235 - accuracy: 0.9621 - val_loss: 0.1119 - val_accuracy: 0.9680\n",
            "Epoch 25/25\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.1177 - accuracy: 0.9638 - val_loss: 0.1033 - val_accuracy: 0.9678\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdc3c0639d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkS7BttyZUey"
      },
      "source": [
        "Advanced EncDec evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhRJVUGlVt6b",
        "outputId": "6163b7a6-28c4-4c40-ef58-8322f83f5dc9"
      },
      "source": [
        "improved_encdec_predictions = improved_encdec.predict(x_test)\n",
        "def get_predictions(model, tokenizer, predictions):\n",
        "  new_predictions = []\n",
        "  for i, prediction in enumerate(predictions):\n",
        "     new_predictions.append(out_to_txt(prediction, tokenizer))\n",
        "  return new_predictions\n",
        "\n",
        "def bleu_score(predictions, originals):\n",
        "  total = 0\n",
        "  for i, prediction in enumerate(predictions):\n",
        "    reference = [prediction]\n",
        "    candidate = originals[i]\n",
        "    score = sentence_bleu(reference, candidate, smoothing_function=smoothie)\n",
        "    total += score\n",
        "  return total / len(predictions) * 100\n",
        "\n",
        "def train_to_predictions(predictions):\n",
        "  new_predictions = []\n",
        "  y_id_to_word = {value: key for key, value in french_tokenizer.word_index.items()}\n",
        "  y_id_to_word[0] = '<PAD>'\n",
        "  for i, prediction in enumerate(predictions):\n",
        "    new_predictions.append(([y_id_to_word[np.max(x)] for x in prediction]))\n",
        "  return new_predictions\n",
        "\n",
        "improved_encdec_predictions = get_predictions(improved_encdec, french_tokenizer, improved_encdec_predictions)\n",
        "print(improved_encdec_predictions[0])\n",
        "y_predictions = train_to_predictions(y_test)\n",
        "print(y_predictions[0])\n",
        "\n",
        "\n",
        "\n",
        "print(\"this is the bleu score of the advanced encdec model:\")\n",
        "print(bleu_score((improved_encdec_predictions), y_predictions))\n"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['chine', 'est', 'généralement', 'occupé', 'en', 'septembre', 'mais', 'il', 'est', 'parfois', 'froid', 'au', 'printemps', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['chine', 'est', 'généralement', 'occupé', 'en', 'septembre', 'mais', 'il', 'est', 'parfois', 'froid', 'au', 'printemps', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "this is the bleu score of the advanced encdec model:\n",
            "39.97476301527965\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}